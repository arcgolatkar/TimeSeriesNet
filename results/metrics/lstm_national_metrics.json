{
  "metrics": {
    "MAE": 4.6999416747962615,
    "MSE": 22.089458505946677,
    "RMSE": 4.6999423938966185,
    "sMAPE": 36.924037475834965,
    "MAPE": 31.169514835968847,
    "R2": -3140046.7710973723
  },
  "predictions": [
    10.378643035888672,
    10.37863540649414,
    10.378664016723633,
    10.378706932067871,
    10.378755569458008,
    10.378761291503906,
    10.378776550292969
  ],
  "actuals": [
    15.075503328344325,
    15.0750515039841,
    15.077434578446002,
    15.078398806647604,
    15.08253590490837,
    15.080324478317142,
    15.081285925355482
  ],
  "config": {
    "model": {
      "name": "LSTM",
      "input_size": 1,
      "hidden_size": 128,
      "num_layers": 3,
      "dropout": 0.2,
      "bidirectional": false
    },
    "data": {
      "data_dir": "src/models/data/processed",
      "sequence_length": 5,
      "forecast_horizon": 1,
      "train_years": [
        2010,
        2017
      ],
      "val_years": [
        2014,
        2020
      ],
      "test_years": [
        2017,
        2023
      ],
      "batch_size": 64,
      "num_workers": 0
    },
    "training": {
      "max_epochs": 150,
      "learning_rate": 0.001,
      "weight_decay": 0.0001,
      "optimizer": "adam",
      "scheduler": "step",
      "step_size": 30,
      "gamma": 0.5,
      "gradient_clip_val": 1.0,
      "early_stopping_patience": 15
    },
    "logging": {
      "experiment_name": "lstm_baseline",
      "log_dir": "results/logs",
      "checkpoint_dir": "results/checkpoints"
    },
    "reproducibility": {
      "seed": 42
    }
  }
}