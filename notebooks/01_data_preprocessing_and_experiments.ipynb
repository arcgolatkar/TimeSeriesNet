{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Scale Transformer for GHG Emission Forecasting\n",
        "## Data Preprocessing and Experiments\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Data download and preprocessing\n",
        "2. Exploratory data analysis\n",
        "3. Training baseline models (ARIMA, Prophet, LSTM)\n",
        "4. Training Multi-Scale Transformer\n",
        "5. Model comparison and evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Download and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "from utils.preprocess_data import GHGDataPreprocessor\n",
        "\n",
        "preprocessor = GHGDataPreprocessor(\n",
        "    raw_data_dir='../data/raw',\n",
        "    processed_data_dir='../data/processed'\n",
        ")\n",
        "\n",
        "preprocessor.process_all()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "with open('../data/processed/facility_series.pkl', 'rb') as f:\n",
        "    facility_series = pickle.load(f)\n",
        "\n",
        "with open('../data/processed/sector_series.pkl', 'rb') as f:\n",
        "    sector_series = pickle.load(f)\n",
        "\n",
        "with open('../data/processed/national_series.pkl', 'rb') as f:\n",
        "    national_series = pickle.load(f)\n",
        "\n",
        "facility_metadata = pd.read_csv('../data/processed/facility_metadata.csv')\n",
        "\n",
        "print(f\"Loaded {len(facility_series)} facility time series\")\n",
        "print(f\"Loaded {len(sector_series)} sector time series\")\n",
        "print(f\"Loaded national time series with {len(national_series)} years\")\n",
        "print(f\"\\nSectors: {list(sector_series.keys())}\")\n",
        "print(f\"Year range: {national_series.index.min()} - {national_series.index.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot national-level emissions over time\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "national_series.plot(ax=ax, marker='o', linewidth=2, markersize=8, color='darkblue')\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Log(CO2e Emissions)', fontsize=12)\n",
        "ax.set_title('National GHG Emissions (2010-2023)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/national_emissions_trend.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"National emissions range: {np.expm1(national_series.min()):.2e} - {np.expm1(national_series.max()):.2e} metric tons CO2e\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot sector-level emissions\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "colors = sns.color_palette(\"husl\", len(sector_series))\n",
        "for (sector, series), color in zip(sector_series.items(), colors):\n",
        "    ax.plot(series.index, series.values, marker='o', label=sector, linewidth=2, color=color)\n",
        "\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Log(CO2e Emissions)', fontsize=12)\n",
        "ax.set_title('Sector-Level GHG Emissions (2010-2023)', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/sector_emissions_trends.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of facility emissions (sample)\n",
        "sample_facilities = list(facility_series.items())[:50]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "for fid, series in sample_facilities:\n",
        "    ax.plot(series.index, series.values, alpha=0.3, linewidth=1)\n",
        "\n",
        "ax.set_xlabel('Year', fontsize=12)\n",
        "ax.set_ylabel('Log(CO2e Emissions)', fontsize=12)\n",
        "ax.set_title('Sample Facility-Level Emissions (50 facilities)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/facility_emissions_sample.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Total facilities: {len(facility_series)}\")\n",
        "print(f\"Average time series length: {np.mean([len(s) for s in facility_series.values()]):.1f} years\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Baseline Models\n",
        "\n",
        "### 3.1 ARIMA Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from baselines.arima_model import evaluate_arima_on_multiple_series\n",
        "\n",
        "print(\"Training ARIMA baseline on facility-level data...\")\n",
        "print(\"(This may take a few minutes)\")\n",
        "print()\n",
        "\n",
        "arima_results = evaluate_arima_on_multiple_series(\n",
        "    facility_series,\n",
        "    train_years=(2010, 2019),\n",
        "    test_years=(2020, 2023),\n",
        "    max_series=100,  # Evaluate on subset for speed\n",
        "    auto_arima_search=True,\n",
        "    seasonal=False\n",
        ")\n",
        "\n",
        "print(\"\\nARIMA Results:\")\n",
        "for metric, value in arima_results['overall_metrics'].items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save results\n",
        "import pickle\n",
        "with open('../results/metrics/arima_results.pkl', 'wb') as f:\n",
        "    pickle.dump(arima_results, f)\n",
        "print(\"\\nSaved ARIMA results to results/metrics/arima_results.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Prophet Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from baselines.prophet_model import evaluate_prophet_on_multiple_series\n",
        "\n",
        "print(\"Training Prophet baseline on facility-level data...\")\n",
        "print(\"(This may take a few minutes)\")\n",
        "print()\n",
        "\n",
        "prophet_results = evaluate_prophet_on_multiple_series(\n",
        "    facility_series,\n",
        "    train_years=(2010, 2019),\n",
        "    test_years=(2020, 2023),\n",
        "    max_series=100,\n",
        "    growth='linear',\n",
        "    yearly_seasonality=False\n",
        ")\n",
        "\n",
        "print(\"\\nProphet Results:\")\n",
        "for metric, value in prophet_results['overall_metrics'].items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save results\n",
        "with open('../results/metrics/prophet_results.pkl', 'wb') as f:\n",
        "    pickle.dump(prophet_results, f)\n",
        "print(\"\\nSaved Prophet results to results/metrics/prophet_results.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 LSTM Baseline\n",
        "\n",
        "**Note:** LSTM training requires more computation. Run via command line:\n",
        "\n",
        "```bash\n",
        "python src/baselines/train_lstm.py --config configs/lstm_config.yaml\n",
        "```\n",
        "\n",
        "This will train the LSTM model and save results to `results/checkpoints/` and metrics to TensorBoard logs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Multi-Scale Transformer\n",
        "\n",
        "**Note:** MST training is compute-intensive and best done with GPU. Run via command line:\n",
        "\n",
        "```bash\n",
        "python src/models/train_mst.py --config configs/mst_config.yaml\n",
        "```\n",
        "\n",
        "**Training features:**\n",
        "- Multi-scale architecture (fine + coarse encoders)\n",
        "- Cross-scale fusion with attention\n",
        "- Hierarchical predictions (facility, sector, national)\n",
        "- Multi-scale loss function\n",
        "- Early stopping and checkpointing\n",
        "\n",
        "**Monitor training:**\n",
        "```bash\n",
        "tensorboard --logdir results/logs\n",
        "```\n",
        "\n",
        "Then open http://localhost:6006 in your browser.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "comparison_data = {\n",
        "    'Model': ['ARIMA', 'Prophet', 'LSTM', 'Multi-Scale Transformer'],\n",
        "    'MAE': [\n",
        "        arima_results['overall_metrics'].get('MAE', 0),\n",
        "        prophet_results['overall_metrics'].get('MAE', 0),\n",
        "        0,  # To be filled from LSTM results file\n",
        "        0   # To be filled from MST results file\n",
        "    ],\n",
        "    'RMSE': [\n",
        "        arima_results['overall_metrics'].get('RMSE', 0),\n",
        "        prophet_results['overall_metrics'].get('RMSE', 0),\n",
        "        0,\n",
        "        0\n",
        "    ],\n",
        "    'sMAPE': [\n",
        "        arima_results['overall_metrics'].get('sMAPE', 0),\n",
        "        prophet_results['overall_metrics'].get('sMAPE', 0),\n",
        "        0,\n",
        "        0\n",
        "    ],\n",
        "    'MASE': [\n",
        "        arima_results['overall_metrics'].get('MASE', 0),\n",
        "        prophet_results['overall_metrics'].get('MASE', 0),\n",
        "        0,\n",
        "        0\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nModel Comparison (Classical Baselines):\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_df[comparison_df['Model'].isin(['ARIMA', 'Prophet'])].to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save to CSV\n",
        "comparison_df.to_csv('../results/metrics/model_comparison.csv', index=False)\n",
        "print(\"\\nSaved comparison to results/metrics/model_comparison.csv\")\n",
        "\n",
        "# Note about LSTM and MST\n",
        "print(\"\\nNote: LSTM and MST results will be added after training completes.\")\n",
        "print(\"Run the training scripts and then use src/utils/evaluate_models.py to generate full comparison.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model comparison (classical baselines)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "metrics = ['MAE', 'RMSE', 'sMAPE', 'MASE']\n",
        "\n",
        "# Only show ARIMA and Prophet for now\n",
        "baseline_df = comparison_df[comparison_df['Model'].isin(['ARIMA', 'Prophet'])]\n",
        "\n",
        "for i, (ax, metric) in enumerate(zip(axes.flat, metrics)):\n",
        "    bars = ax.bar(baseline_df['Model'], baseline_df[metric], alpha=0.7, \n",
        "                   color=['#1f77b4', '#ff7f0e'])\n",
        "    ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel(metric, fontsize=10)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    ax.set_xticklabels(baseline_df['Model'], rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        if height > 0:\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.3f}',\n",
        "                   ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/baseline_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved comparison plot to results/figures/baseline_comparison.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample predictions\n",
        "# Get a sample facility's predictions from ARIMA results\n",
        "if len(arima_results['series_results']) > 0:\n",
        "    sample_id = list(arima_results['series_results'].keys())[0]\n",
        "    sample_result = arima_results['series_results'][sample_id]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    years = np.arange(2020, 2020 + len(sample_result['actuals']))\n",
        "    ax.plot(years, sample_result['actuals'], marker='o', label='Actual', \n",
        "            linewidth=2, markersize=8)\n",
        "    ax.plot(years, sample_result['predictions'], marker='s', label='ARIMA Prediction', \n",
        "            linewidth=2, markersize=8, alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel('Year', fontsize=12)\n",
        "    ax.set_ylabel('Log(CO2e Emissions)', fontsize=12)\n",
        "    ax.set_title(f'Sample Facility Predictions (Facility {sample_id})', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../results/figures/sample_predictions.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Sample facility MAE: {sample_result['metrics']['MAE']:.4f}\")\n",
        "else:\n",
        "    print(\"No predictions available to visualize.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"PROJECT SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nüìä Data Statistics:\")\n",
        "print(f\"  - Facilities: {len(facility_series)}\")\n",
        "print(f\"  - Sectors: {len(sector_series)}\")\n",
        "print(f\"  - Sector names: {', '.join(sector_series.keys())}\")\n",
        "print(f\"  - Years: {national_series.index.min()} - {national_series.index.max()}\")\n",
        "print(f\"  - Total national emissions range: {np.expm1(national_series.min()):.2e} - {np.expm1(national_series.max()):.2e} metric tons CO2e\")\n",
        "\n",
        "print(f\"\\nüéØ Models Evaluated:\")\n",
        "print(f\"  ‚úì ARIMA: Trained on {arima_results['num_series']} facilities\")\n",
        "print(f\"  ‚úì Prophet: Trained on {prophet_results['num_series']} facilities\")\n",
        "print(f\"  ‚è≥ LSTM: Run via command line (python src/baselines/train_lstm.py)\")\n",
        "print(f\"  ‚è≥ Multi-Scale Transformer: Run via command line (python src/models/train_mst.py)\")\n",
        "\n",
        "print(f\"\\nüèÜ Best Performing Model (Classical Baselines):\")\n",
        "best_model_idx = comparison_df[comparison_df['Model'].isin(['ARIMA', 'Prophet'])]['MAE'].idxmin()\n",
        "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
        "best_mae = comparison_df.loc[best_model_idx, 'MAE']\n",
        "print(f\"  - {best_model} (MAE: {best_mae:.4f})\")\n",
        "\n",
        "print(f\"\\nüìÅ Results Saved To:\")\n",
        "print(f\"  - Metrics: results/metrics/\")\n",
        "print(f\"  - Figures: results/figures/\")\n",
        "print(f\"  - Comparison table: results/metrics/model_comparison.csv\")\n",
        "\n",
        "print(f\"\\nüìù Next Steps:\")\n",
        "print(f\"  1. Train LSTM: python src/baselines/train_lstm.py --config configs/lstm_config.yaml\")\n",
        "print(f\"  2. Train MST: python src/models/train_mst.py --config configs/mst_config.yaml\")\n",
        "print(f\"  3. Generate full comparison: python src/utils/evaluate_models.py\")\n",
        "print(f\"  4. Fill in interim report: report/interim_report_template.md\")\n",
        "print(f\"  5. Create presentation slides using: report/presentation_outline.md\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Additional Analysis (Optional)\n",
        "\n",
        "Below are some optional analysis cells you can run to gain more insights:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of emissions by sector\n",
        "sector_totals = {sector: np.expm1(series.mean()) for sector, series in sector_series.items()}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sectors = list(sector_totals.keys())\n",
        "totals = list(sector_totals.values())\n",
        "\n",
        "bars = ax.barh(sectors, totals, alpha=0.7, color=sns.color_palette(\"husl\", len(sectors)))\n",
        "ax.set_xlabel('Average Annual CO2e Emissions (metric tons)', fontsize=12)\n",
        "ax.set_title('Average Emissions by Sector (2010-2023)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, value) in enumerate(zip(bars, totals)):\n",
        "    ax.text(value, i, f'{value:.2e}', va='center', fontsize=9, \n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/sector_emissions_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Emission trends (percentage change from 2010 to 2023)\n",
        "print(\"Emission Trends (2010 to 2023):\\n\")\n",
        "print(f\"{'Level':<30} {'2010 Emissions':<20} {'2023 Emissions':<20} {'% Change':<15}\")\n",
        "print(\"=\"*85)\n",
        "\n",
        "# National trend\n",
        "nat_2010 = np.expm1(national_series[2010])\n",
        "nat_2023 = np.expm1(national_series[2023])\n",
        "nat_change = ((nat_2023 - nat_2010) / nat_2010) * 100\n",
        "print(f\"{'National':<30} {nat_2010:<20.2e} {nat_2023:<20.2e} {nat_change:>+14.2f}%\")\n",
        "\n",
        "# Sector trends\n",
        "for sector, series in sector_series.items():\n",
        "    if 2010 in series.index and 2023 in series.index:\n",
        "        sec_2010 = np.expm1(series[2010])\n",
        "        sec_2023 = np.expm1(series[2023])\n",
        "        sec_change = ((sec_2023 - sec_2010) / sec_2010) * 100\n",
        "        print(f\"{sector:<30} {sec_2010:<20.2e} {sec_2023:<20.2e} {sec_change:>+14.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Notebook Complete!\n",
        "\n",
        "You've successfully:\n",
        "1. ‚úÖ Downloaded/generated EPA GHGRP data\n",
        "2. ‚úÖ Preprocessed data into hierarchical time series\n",
        "3. ‚úÖ Performed exploratory data analysis with visualizations\n",
        "4. ‚úÖ Trained ARIMA and Prophet baseline models\n",
        "5. ‚úÖ Generated comparison metrics and plots\n",
        "\n",
        "### üìä Generated Files:\n",
        "- **Data:** `data/processed/*.pkl` (facility, sector, national time series)\n",
        "- **Metrics:** `results/metrics/model_comparison.csv`\n",
        "- **Figures:** `results/figures/*.png` (6+ publication-quality plots)\n",
        "\n",
        "### üöÄ Next Steps:\n",
        "\n",
        "**1. Train Deep Learning Models:**\n",
        "```bash\n",
        "# LSTM\n",
        "python src/baselines/train_lstm.py --config configs/lstm_config.yaml\n",
        "\n",
        "# Multi-Scale Transformer\n",
        "python src/models/train_mst.py --config configs/mst_config.yaml\n",
        "```\n",
        "\n",
        "**2. Generate Full Model Comparison:**\n",
        "```bash\n",
        "python src/utils/evaluate_models.py\n",
        "```\n",
        "\n",
        "**3. Complete Interim Report:**\n",
        "- Open `report/interim_report_template.md`\n",
        "- Fill in [INSERT] placeholders with your results\n",
        "- Add figures from `results/figures/`\n",
        "\n",
        "**4. Create Presentation:**\n",
        "- Use `report/presentation_outline.md` as guide\n",
        "- Create 15-16 slides with diagrams and results\n",
        "\n",
        "**5. Monitor Training (optional):**\n",
        "```bash\n",
        "tensorboard --logdir results/logs\n",
        "```\n",
        "\n",
        "### üìö Documentation:\n",
        "- **Project Summary:** `PROJECT_SUMMARY.md`\n",
        "- **Full README:** `README.md`\n",
        "- **Report Template:** `report/interim_report_template.md`\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck with your interim report! üéì**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download EPA GHGRP data\n",
        "from utils.download_data import EPADataDownloader\n",
        "\n",
        "downloader = EPADataDownloader(output_dir='../data/raw')\n",
        "\n",
        "# Try to download real data, or create sample data\n",
        "print(\"Attempting to download EPA data...\")\n",
        "# data = downloader.download_all()\n",
        "data = None\n",
        "\n",
        "if not data:\n",
        "    print(\"Creating sample data for demonstration...\")\n",
        "    data = downloader.create_sample_data()\n",
        "\n",
        "print(f\"\\nDownloaded {len(data)} datasets\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
